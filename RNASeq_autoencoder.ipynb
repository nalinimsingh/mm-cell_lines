{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 624,
   "id": "contrary-dylan",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import Lasso, LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "\n",
    "import CCLE_utils\n",
    "import MMRF_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "fallen-ottawa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/Users/nalinisingh/datasets/depmap/'\n",
    "mmrf_rna_dir = '/Users/nalinisingh/datasets/multiple_myeloma/MMRF_CoMMpass_IA15a_E74GTF_Cufflinks_Gene_FPKM.txt'\n",
    "rna_map_path = 'Ensembl_HGNC_map_042421.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weekly-projector",
   "metadata": {},
   "source": [
    "## Load CCLE Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "id": "unauthorized-coast",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ENSG00000000003</th>\n",
       "      <th>ENSG00000000005</th>\n",
       "      <th>ENSG00000000419</th>\n",
       "      <th>ENSG00000000457</th>\n",
       "      <th>ENSG00000000460</th>\n",
       "      <th>ENSG00000000938</th>\n",
       "      <th>ENSG00000000971</th>\n",
       "      <th>ENSG00000001036</th>\n",
       "      <th>ENSG00000001084</th>\n",
       "      <th>ENSG00000001167</th>\n",
       "      <th>...</th>\n",
       "      <th>ENSG00000185097</th>\n",
       "      <th>ENSG00000204293</th>\n",
       "      <th>ENSG00000187600</th>\n",
       "      <th>ENSG00000197376</th>\n",
       "      <th>ENSG00000235249</th>\n",
       "      <th>ENSG00000116957</th>\n",
       "      <th>ENSG00000227135</th>\n",
       "      <th>ENSG00000145075</th>\n",
       "      <th>ENSG00000187951</th>\n",
       "      <th>ENSG00000168255</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.990501</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.273702</td>\n",
       "      <td>2.765535</td>\n",
       "      <td>4.480265</td>\n",
       "      <td>0.028569</td>\n",
       "      <td>1.269033</td>\n",
       "      <td>3.058316</td>\n",
       "      <td>6.483171</td>\n",
       "      <td>5.053980</td>\n",
       "      <td>...</td>\n",
       "      <td>0.070389</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.070389</td>\n",
       "      <td>5.761019</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028569</td>\n",
       "      <td>1.214125</td>\n",
       "      <td>5.781884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.209843</td>\n",
       "      <td>0.545968</td>\n",
       "      <td>7.070604</td>\n",
       "      <td>2.538538</td>\n",
       "      <td>3.510962</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.176323</td>\n",
       "      <td>3.836934</td>\n",
       "      <td>4.200850</td>\n",
       "      <td>3.832890</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014355</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014355</td>\n",
       "      <td>5.771357</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.090853</td>\n",
       "      <td>1.835924</td>\n",
       "      <td>4.704319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.779260</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.346425</td>\n",
       "      <td>2.339137</td>\n",
       "      <td>4.254745</td>\n",
       "      <td>0.056584</td>\n",
       "      <td>1.339137</td>\n",
       "      <td>6.724241</td>\n",
       "      <td>3.671293</td>\n",
       "      <td>3.775051</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014355</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014355</td>\n",
       "      <td>4.744699</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.823749</td>\n",
       "      <td>4.931683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.726831</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.086189</td>\n",
       "      <td>2.543496</td>\n",
       "      <td>3.102658</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.914565</td>\n",
       "      <td>6.099716</td>\n",
       "      <td>4.475733</td>\n",
       "      <td>4.294253</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.164304</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.871844</td>\n",
       "      <td>3.858976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.465648</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.435462</td>\n",
       "      <td>2.414136</td>\n",
       "      <td>3.864929</td>\n",
       "      <td>0.831877</td>\n",
       "      <td>7.198003</td>\n",
       "      <td>5.452530</td>\n",
       "      <td>7.112492</td>\n",
       "      <td>4.710944</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014355</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014355</td>\n",
       "      <td>4.673556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.324811</td>\n",
       "      <td>4.990501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1371</th>\n",
       "      <td>4.173127</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.400879</td>\n",
       "      <td>1.807355</td>\n",
       "      <td>3.303050</td>\n",
       "      <td>0.014355</td>\n",
       "      <td>0.137504</td>\n",
       "      <td>4.944858</td>\n",
       "      <td>4.528571</td>\n",
       "      <td>4.383359</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.513491</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014355</td>\n",
       "      <td>1.280956</td>\n",
       "      <td>5.102658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1372</th>\n",
       "      <td>0.097611</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.428276</td>\n",
       "      <td>3.257011</td>\n",
       "      <td>4.980482</td>\n",
       "      <td>0.411426</td>\n",
       "      <td>0.124328</td>\n",
       "      <td>0.704872</td>\n",
       "      <td>4.829342</td>\n",
       "      <td>5.393348</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014355</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014355</td>\n",
       "      <td>5.553361</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014355</td>\n",
       "      <td>2.939227</td>\n",
       "      <td>6.341630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1373</th>\n",
       "      <td>5.045268</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.991749</td>\n",
       "      <td>1.807355</td>\n",
       "      <td>3.270529</td>\n",
       "      <td>0.028569</td>\n",
       "      <td>3.333424</td>\n",
       "      <td>6.819796</td>\n",
       "      <td>5.395063</td>\n",
       "      <td>3.727920</td>\n",
       "      <td>...</td>\n",
       "      <td>0.070389</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.070389</td>\n",
       "      <td>4.887525</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014355</td>\n",
       "      <td>1.510962</td>\n",
       "      <td>4.607626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1374</th>\n",
       "      <td>5.805292</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.792855</td>\n",
       "      <td>2.482848</td>\n",
       "      <td>3.903038</td>\n",
       "      <td>0.028569</td>\n",
       "      <td>4.124328</td>\n",
       "      <td>6.816600</td>\n",
       "      <td>4.458119</td>\n",
       "      <td>3.664483</td>\n",
       "      <td>...</td>\n",
       "      <td>0.084064</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.084064</td>\n",
       "      <td>4.040016</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137504</td>\n",
       "      <td>0.757023</td>\n",
       "      <td>4.787119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1375</th>\n",
       "      <td>4.870858</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.077457</td>\n",
       "      <td>2.304511</td>\n",
       "      <td>3.836934</td>\n",
       "      <td>0.201634</td>\n",
       "      <td>1.339137</td>\n",
       "      <td>3.491853</td>\n",
       "      <td>3.940167</td>\n",
       "      <td>4.621759</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.305241</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.648465</td>\n",
       "      <td>4.452859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1376 rows × 18927 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ENSG00000000003  ENSG00000000005  ENSG00000000419  ENSG00000000457  \\\n",
       "0            4.990501         0.000000         7.273702         2.765535   \n",
       "1            5.209843         0.545968         7.070604         2.538538   \n",
       "2            3.779260         0.000000         7.346425         2.339137   \n",
       "3            5.726831         0.000000         7.086189         2.543496   \n",
       "4            7.465648         0.000000         6.435462         2.414136   \n",
       "...               ...              ...              ...              ...   \n",
       "1371         4.173127         0.000000         6.400879         1.807355   \n",
       "1372         0.097611         0.000000         6.428276         3.257011   \n",
       "1373         5.045268         0.000000         6.991749         1.807355   \n",
       "1374         5.805292         0.000000         7.792855         2.482848   \n",
       "1375         4.870858         0.000000         6.077457         2.304511   \n",
       "\n",
       "      ENSG00000000460  ENSG00000000938  ENSG00000000971  ENSG00000001036  \\\n",
       "0            4.480265         0.028569         1.269033         3.058316   \n",
       "1            3.510962         0.000000         0.176323         3.836934   \n",
       "2            4.254745         0.056584         1.339137         6.724241   \n",
       "3            3.102658         0.000000         5.914565         6.099716   \n",
       "4            3.864929         0.831877         7.198003         5.452530   \n",
       "...               ...              ...              ...              ...   \n",
       "1371         3.303050         0.014355         0.137504         4.944858   \n",
       "1372         4.980482         0.411426         0.124328         0.704872   \n",
       "1373         3.270529         0.028569         3.333424         6.819796   \n",
       "1374         3.903038         0.028569         4.124328         6.816600   \n",
       "1375         3.836934         0.201634         1.339137         3.491853   \n",
       "\n",
       "      ENSG00000001084  ENSG00000001167  ...  ENSG00000185097  ENSG00000204293  \\\n",
       "0            6.483171         5.053980  ...         0.070389              0.0   \n",
       "1            4.200850         3.832890  ...         0.014355              0.0   \n",
       "2            3.671293         3.775051  ...         0.014355              0.0   \n",
       "3            4.475733         4.294253  ...         0.000000              0.0   \n",
       "4            7.112492         4.710944  ...         0.014355              0.0   \n",
       "...               ...              ...  ...              ...              ...   \n",
       "1371         4.528571         4.383359  ...         0.000000              0.0   \n",
       "1372         4.829342         5.393348  ...         0.014355              0.0   \n",
       "1373         5.395063         3.727920  ...         0.070389              0.0   \n",
       "1374         4.458119         3.664483  ...         0.084064              0.0   \n",
       "1375         3.940167         4.621759  ...         0.000000              0.0   \n",
       "\n",
       "      ENSG00000187600  ENSG00000197376  ENSG00000235249  ENSG00000116957  \\\n",
       "0                 0.0              0.0         0.070389         5.761019   \n",
       "1                 0.0              0.0         0.014355         5.771357   \n",
       "2                 0.0              0.0         0.014355         4.744699   \n",
       "3                 0.0              0.0         0.000000         4.164304   \n",
       "4                 0.0              0.0         0.014355         4.673556   \n",
       "...               ...              ...              ...              ...   \n",
       "1371              0.0              0.0         0.000000         4.513491   \n",
       "1372              0.0              0.0         0.014355         5.553361   \n",
       "1373              0.0              0.0         0.070389         4.887525   \n",
       "1374              0.0              0.0         0.084064         4.040016   \n",
       "1375              0.0              0.0         0.000000         4.305241   \n",
       "\n",
       "      ENSG00000227135  ENSG00000145075  ENSG00000187951  ENSG00000168255  \n",
       "0                 0.0         0.028569         1.214125         5.781884  \n",
       "1                 0.0         1.090853         1.835924         4.704319  \n",
       "2                 0.0         0.000000         1.823749         4.931683  \n",
       "3                 0.0         0.000000         0.871844         3.858976  \n",
       "4                 0.0         0.000000         2.324811         4.990501  \n",
       "...               ...              ...              ...              ...  \n",
       "1371              0.0         0.014355         1.280956         5.102658  \n",
       "1372              0.0         0.014355         2.939227         6.341630  \n",
       "1373              0.0         0.014355         1.510962         4.607626  \n",
       "1374              0.0         0.137504         0.757023         4.787119  \n",
       "1375              0.0         0.000000         2.648465         4.452859  \n",
       "\n",
       "[1376 rows x 18927 columns]"
      ]
     },
     "execution_count": 651,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CCLE_utils.get_ccle_rnaseq_with_ensembl(os.path.join(data_dir,'CCLE_expression.csv'), rna_map_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "id": "perfect-arthritis",
   "metadata": {},
   "outputs": [],
   "source": [
    "ccle = pd.read_csv(os.path.join(data_dir,'CCLE_expression.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "id": "cognitive-kenya",
   "metadata": {},
   "outputs": [],
   "source": [
    "ccle = ccle.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "id": "local-leonard",
   "metadata": {},
   "outputs": [],
   "source": [
    "rna_map = pd.read_csv(rna_map_path)\n",
    "rna_map_dict = {}\n",
    "for _, row in rna_map.iterrows():\n",
    "    rna_map_dict[row['HGNC_ID']] = row['Ensembl_ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "id": "molecular-hearts",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hgnc_to_ensembl(hgnc_df):\n",
    "    to_del = []\n",
    "    for col in hgnc_df:\n",
    "        if(col not in rna_map_dict):\n",
    "            to_del.append(col)\n",
    "            \n",
    "    hgnc_df.drop(columns=to_del, inplace=True)\n",
    "    \n",
    "    ensembl_df = hgnc_df.rename(columns=rna_map_dict)\n",
    "    return ensembl_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "id": "accredited-personal",
   "metadata": {},
   "outputs": [],
   "source": [
    "ccle_ensembl = hgnc_to_ensembl(ccle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "id": "linear-adelaide",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "n_points = ccle_ensembl.shape[0]\n",
    "\n",
    "n_train = int(n_points*0.7)\n",
    "n_val = int(n_points*0.1)\n",
    "n_test = n_points-(n_train+n_val)\n",
    "\n",
    "train_ccle = ccle_ensembl.loc[:n_train,:].values\n",
    "val_ccle = ccle_ensembl.loc[n_train:n_train+n_val,:].values\n",
    "test_ccle = ccle_ensembl.loc[n_train+n_val:,:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "id": "revolutionary-fighter",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 500\n",
    "ccle_pca = PCA(n_components = n_components)\n",
    "ccle_pca.fit(train_rna)\n",
    "\n",
    "train_ccle_pca = ccle_pca.transform(train_ccle)\n",
    "val_ccle_pca = pca.transform(val_ccle)\n",
    "test_ccle_pca = pca.transform(test_ccle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "happy-encyclopedia",
   "metadata": {},
   "source": [
    "# Load MMRF Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 803,
   "id": "direct-coffee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading from: /Users/nalinisingh/dev/ml_mmrf/ml_mmrf/output/cleaned_mm_fold_2mos_pfs_ind_seed0.pkl\n",
      "pids\n",
      "(494,)\n",
      "x\n",
      "(494, 33, 16)\n",
      "m\n",
      "(494, 33, 16)\n",
      "feature_names_x\n",
      "(16,)\n",
      "['cbc_abs_neut' 'chem_albumin' 'chem_bun' 'chem_calcium' 'chem_creatinine'\n",
      " 'chem_glucose' 'cbc_hemoglobin' 'serum_kappa' 'serum_m_protein'\n",
      " 'cbc_platelet' 'chem_totprot' 'cbc_wbc' 'serum_iga' 'serum_igg'\n",
      " 'serum_igm' 'serum_lambda']\n",
      "ys_seq\n",
      "(494, 1)\n",
      "ce\n",
      "(494, 1)\n",
      "feature_names_y\n",
      "(1,)\n",
      "['progression free survival (all)']\n",
      "b\n",
      "(494, 16)\n",
      "feature_names\n",
      "(16,)\n",
      "Index(['iss', 'age', 'gender', 'ecog', 'serum_beta2_microglobulin', 'PC1',\n",
      "       'PC2', 'PC3', 'PC4', 'PC5', 'heavy_chain', 'igg_type', 'iga_type',\n",
      "       'igm_type', 'kappa_type', 'lambda_type'],\n",
      "      dtype='object')\n",
      "a\n",
      "(494, 33, 9)\n",
      "m_a\n",
      "(494, 33, 6)\n",
      "feature_names_a\n",
      "(9,)\n",
      "['local_clock' 'Bor' 'Car' 'Cyc' 'Dex' 'Len' 'line1' 'line2' 'line3plus']\n",
      "\n",
      "Preprocess patient data in MMRF\n",
      "Keep first 3 clinical visits.\n",
      "(494, 93)\n",
      "Keep first 3 clinical visits.\n",
      "(200, 93)\n",
      "Keep first 3 clinical visits.\n",
      "(269, 93)\n",
      "\n",
      "Preprocess patient genomic data in MMRF...\n",
      "Reading /Users/nalinisingh/datasets/multiple_myeloma/MMRF_CoMMpass_IA15a_E74GTF_Salmon_Gene_TPM.txt\n",
      "Raw data shape:\n",
      "(57997, 922)\n",
      "0 out of 57997 genes have missing data \n",
      "Using raw genomic data...\n",
      "Created new dataframe...\n",
      "(774, 57998)\n",
      "\n",
      "Merging patient data with genomic data...\n"
     ]
    }
   ],
   "source": [
    "train_patient_all = pd.DataFrame()\n",
    "valid_patient_all = pd.DataFrame()\n",
    "test_patient_all = pd.DataFrame()\n",
    "\n",
    "for ind in [1]:\n",
    "    data_filename = '/Users/nalinisingh/dev/ml_mmrf/ml_mmrf/output/cleaned_mm_fold_2mos_pfs_ind_seed0.pkl'#%(ind)\n",
    "    train, test, valid = MMRF_utils.get_train_test_valid(data_filename, ind, show_features=True)\n",
    "\n",
    "    print('\\nPreprocess patient data in MMRF')\n",
    "    # include the first n clinical visit data for each patient (default 0)\n",
    "    train_df = MMRF_utils.preprocess_patient_data(train, num_clin_visits=3)  \n",
    "    print(train_df.shape)\n",
    "\n",
    "    valid_df = MMRF_utils.preprocess_patient_data(valid, num_clin_visits=3)  \n",
    "    print(valid_df.shape)\n",
    "\n",
    "    test_df = MMRF_utils.preprocess_patient_data(test, num_clin_visits=3)  \n",
    "    print(test_df.shape)\n",
    "\n",
    "    print('\\nPreprocess patient genomic data in MMRF...')\n",
    "    genomic_fn = '/Users/nalinisingh/datasets/multiple_myeloma/MMRF_CoMMpass_IA15a_E74GTF_Salmon_Gene_TPM.txt'\n",
    "    genomic_df = MMRF_utils.preprocess_genomic_data(genomic_fn, nPCA=0)\n",
    "    print(genomic_df.shape)\n",
    "\n",
    "    print('\\nMerging patient data with genomic data...')\n",
    "    train_patient_all = train_patient_genomic.append(train_df.merge(genomic_df, left_on='pids', right_on='pids'))\n",
    "\n",
    "    valid_patient_all = valid_patient_genomic.append(valid_df.merge(genomic_df, left_on='pids', right_on='pids'))\n",
    "\n",
    "    test_patient_all = test_patient_genomic.append(test_df.merge(genomic_df, left_on='pids', right_on='pids'))\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 800,
   "id": "fourth-peoples",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pfs = train_patient_all['pfs']\n",
    "valid_pfs = valid_patient_all['pfs']\n",
    "test_pfs = test_patient_all['pfs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 771,
   "id": "reasonable-railway",
   "metadata": {},
   "outputs": [],
   "source": [
    "bor_train_patient_all = train_patient_all[train_patient_all['Bor1']==True]\n",
    "bor_valid_patient_all = valid_patient_all[valid_patient_all['Bor1']==True]\n",
    "bor_test_patient_all = test_patient_all[test_patient_all['Bor1']==True]\n",
    "\n",
    "bor_train_pfs = bor_train_patient_all['pfs']\n",
    "bor_valid_pfs = bor_valid_patient_all['pfs']\n",
    "bor_test_pfs = bor_test_patient_all['pfs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 772,
   "id": "african-paragraph",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nalinisingh/anaconda3/envs/mm_disease_prog/lib/python3.8/site-packages/pandas/core/frame.py:4308: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    }
   ],
   "source": [
    "def drop_unnecessary_cols(genomic_df):\n",
    "    to_del = []\n",
    "    for col in genomic_df:\n",
    "        if(col not in cell_line_ensembl.columns):\n",
    "            to_del.append(col)\n",
    "            \n",
    "    genomic_df.drop(columns=to_del, inplace=True)\n",
    "\n",
    "bor_train_patient_all_mat = bor_train_patient_genomic.values[:,2:]\n",
    "bor_valid_patient_all_mat = bor_valid_patient_genomic.values[:,2:]\n",
    "bor_test_patient_all_mat = bor_test_patient_genomic.values[:,2:]\n",
    "\n",
    "drop_unnecessary_cols(train_patient_genomic)\n",
    "drop_unnecessary_cols(valid_patient_genomic)\n",
    "drop_unnecessary_cols(test_patient_genomic)\n",
    "\n",
    "train_patient_genomic = train_patient_all[ccle_ensembl.columns]\n",
    "valid_patient_genomic = valid_patient_all[ccle_ensembl.columns]\n",
    "test_patient_genomic = test_patient_all[ccle_ensembl.columns]\n",
    "\n",
    "bor_train_patient_genomic = bor_train_patient_all[cell_line_ensembl.columns]\n",
    "bor_valid_patient_genomic = bor_valid_patient_all[cell_line_ensembl.columns]\n",
    "bor_test_patient_genomic = bor_test_patient_all[cell_line_ensembl.columns]\n",
    "\n",
    "def drop_ensembl_cols(df):\n",
    "    to_keep = []\n",
    "    for col in df.columns:\n",
    "        if((col not in cell_line_ensembl.columns) and (col not in ['pfs','pids']) and ('ERCC' not in col) and ('ENSG' not in col)):\n",
    "            to_keep.append(col)\n",
    "            \n",
    "    return df[to_keep]\n",
    "            \n",
    "train_patient_meddata = drop_ensembl_cols(train_patient_all)\n",
    "valid_patient_meddata = drop_ensembl_cols(valid_patient_all)\n",
    "test_patient_meddata = drop_ensembl_cols(test_patient_all)\n",
    "\n",
    "bor_train_patient_meddata = drop_ensembl_cols(bor_train_patient_all)\n",
    "bor_valid_patient_meddata = drop_ensembl_cols(bor_valid_patient_all)\n",
    "bor_test_patient_meddata = drop_ensembl_cols(bor_test_patient_all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 777,
   "id": "obvious-beads",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert((ccle_ensembl.columns==train_patient_genomic.columns).all())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complimentary-mineral",
   "metadata": {},
   "source": [
    "## Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 778,
   "id": "visible-alloy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_autoencoder(encoding_dim):\n",
    "    out_shape = train_patient_genomic.shape[1]\n",
    "    # This is our input image\n",
    "    input_rna = keras.Input(shape=(out_shape,))\n",
    "\n",
    "    # \"encoded\" is the encoded representation of the input\n",
    "    encoded = layers.Dense(4*encoding_dim, activation='relu')(input_rna)\n",
    "    encoded = layers.Dense(2*encoding_dim, activation='relu')(encoded)\n",
    "    encoded = layers.Dense(encoding_dim, activation=None)(encoded)\n",
    "\n",
    "    # \"decoded\" is the lossy reconstruction of the input\n",
    "    decoded = layers.Dense(4*encoding_dim, activation='relu')(encoded)                                                          \n",
    "    decoded = layers.Dense(2*encoding_dim, activation='relu')(decoded)\n",
    "    decoded = layers.Dense(out_shape, activation=None)(decoded)\n",
    "\n",
    "    # This model maps an input to its reconstruction\n",
    "    autoencoder = keras.Model(input_rna, decoded)\n",
    "    autoencoder.compile(optimizer='adam', loss='MSE')\n",
    "    \n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 779,
   "id": "fitting-wagon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8cb7ed8af0>"
      ]
     },
     "execution_count": 779,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mmrf_ae = get_autoencoder(64)\n",
    "mmrf_ae.fit(train_patient_genomic, train_patient_genomic,\n",
    "                epochs=300,\n",
    "                batch_size=64,\n",
    "                shuffle=True,\n",
    "                validation_data=(valid_patient_genomic, valid_patient_genomic),\n",
    "                verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 780,
   "id": "supported-block",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8c1ddb4df0>"
      ]
     },
     "execution_count": 780,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bor_ae = get_autoencoder(64)\n",
    "bor_ae.fit(bor_train_patient_genomic, bor_train_patient_genomic,\n",
    "                epochs=300,\n",
    "                batch_size=64,\n",
    "                shuffle=True,\n",
    "                validation_data=(bor_valid_patient_genomic, bor_valid_patient_genomic),\n",
    "                verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 781,
   "id": "everyday-population",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8da59aa6d0>"
      ]
     },
     "execution_count": 781,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ccle_ae = get_autoencoder(64)\n",
    "ccle_ae.fit(train_ccle, train_ccle,\n",
    "                epochs=600,\n",
    "                batch_size=64,\n",
    "                shuffle=True,\n",
    "                validation_data=(val_ccle, val_ccle),\n",
    "                verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 782,
   "id": "objective-daughter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8bc06c2430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Predicted Component')"
      ]
     },
     "execution_count": 782,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVMAAAE9CAYAAAC2tYFeAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAivUlEQVR4nO3de5RdZZnn8e+PSgEFopWQmAkVYkBZMCgtiSWgqC24JMAoRFq5tD1GGk33tLK8piUtPSDigGZahF7e0oAGRS4ihOigMXKxHZRAhQRCwEhEkBSXREJQIYMheeaP/Z7kJKlzalfV3nXOqfp91jrr7P3u21Oe+LD3fm+KCMzMbGh2a3QAZmYjgZOpmVkBnEzNzArgZGpmVgAnUzOzAjiZmpkVYEyjAyjD+PHjY+rUqY0Ow8xGmGXLlv0hIib0tW1EJtOpU6fS09PT6DDMbISR9FitbX7MNzMrgJOpmVkBnEzNzArgZGpmVgAnUzOzAjiZmpkVwMnUzKwAI7KdqZlZPQuX9zJv8Wqe2LiJ/To7mDPjYGZO6xrSOZ1MzWxUWbi8l7k3rmTT5i0A9G7cxNwbVwIMKaH6Md/MRpV5i1dvS6QVmzZvYd7i1UM6r5OpmY0qT2zcNKDyvJxMzWxU2a+zY0DleTmZmtmoMmfGwXS0t+1Q1tHexpwZBw/pvK6AMrNRpVLJ5Np8M7Mhmjmta8jJc2d+zDczK4CTqZlZAZxMzcwK4GRqZlYAJ1MzswI4mZqZFcDJ1MysAE6mZmYFcDI1MyuAk6mZWQGcTM3MCuBkamZWACdTM7MCOJmamRXAydTMrAClJlNJnZJukPRrSQ9JepOkcZKWSHo4fY9N+0rSZZLWSLpf0vSq88xK+z8saVaZMZuZDUbZd6aXAj+JiEOA1wMPAecAt0bEQcCtaR3gBOCg9JkNfB1A0jjgPOBI4AjgvEoCNjNrFqUlU0mvAN4GXAEQEX+JiI3AycCCtNsCYGZaPhm4KjJ3AZ2SJgEzgCURsSEingWWAMeXFbeZ2WCUeWd6ALAe+Jak5ZIul7Q3MDEinkz7PAVMTMtdwONVx69NZbXKzcyaRpnJdAwwHfh6REwDnmf7Iz0AERFAFHExSbMl9UjqWb9+fRGnNDPLrcxkuhZYGxFL0/oNZMn16fT4Tvpel7b3AvtXHT85ldUq30FEzI+I7ojonjBhQqF/iJlZf0pLphHxFPC4pMpk1O8AHgQWAZUa+VnAzWl5EfCBVKt/FPBceh2wGDhO0thU8XRcKjMzaxplT/V8NnC1pN2BR4AzyRL49ZLOAh4DTk373gKcCKwBXkj7EhEbJH0euCftd0FEbCg5bjOzAVH22nJk6e7ujp6enkaHYWYjjKRlEdHd1zb3gDIzK4CTqZlZAZxMzcwK4GRqZlYAJ1MzswI4mZqZFcDJ1MysAE6mZmYFcDI1MyuAk6mZWQGcTM3MCuBkamZWACdTM7MCOJmamRXAydTMrABOpmZmBXAyNTMrgJOpmVkBnEzNzArgZGpmVgAnUzOzAjiZmpkVwMnUzKwATqZmZgVwMjUzK4CTqZlZAZxMzcwK4GRqZlaAUpOppEclrZS0QlJPKhsnaYmkh9P32FQuSZdJWiPpfknTq84zK+3/sKRZZcZsZjYYw3FnekxEHB4R3Wn9HODWiDgIuDWtA5wAHJQ+s4GvQ5Z8gfOAI4EjgPMqCdjMrFk04jH/ZGBBWl4AzKwqvyoydwGdkiYBM4AlEbEhIp4FlgDHD3PMZmZ1lZ1MA/ippGWSZqeyiRHxZFp+CpiYlruAx6uOXZvKapWbmTWNMSWf/y0R0SvplcASSb+u3hgRISmKuFBK1rMBpkyZUsQpzcxyK/XONCJ60/c64Cayd55Pp8d30ve6tHsvsH/V4ZNTWa3yna81PyK6I6J7woQJRf8pZmZ1lZZMJe0taZ/KMnAc8ACwCKjUyM8Cbk7Li4APpFr9o4Dn0uuAxcBxksamiqfjUpmZWdMo8zF/InCTpMp1vhcRP5F0D3C9pLOAx4BT0/63ACcCa4AXgDMBImKDpM8D96T9LoiIDSXGbWY2YIoo5JVlU+nu7o6enp5Gh2FmI4ykZVXNPHfgHlBmZgVwMjUzK4CTqZlZAZxMzcwK4GRqZlaAfpOppPflKTMzG83y3JnOzVlmZjZq1Wy0L+kEskb0XZIuq9r0cuClsgMzM2sl9XpAPQH0ACcBy6rK/wR8osygzMxaTc1kGhH3AfdJ+l5EbB7GmMzMWk6evvlHSDofeFXaX2Sj5x1YZmBmZq0kTzK9guyxfhmwpdxwzMxaU55k+lxE/Lj0SMzMWlieZHq7pHnAjcCLlcKIuLe0qMzMWkyeZHpk+q4ediqAY4sPx8ysNfWbTCPimOEIxMysleXpTjpR0hWSfpzWD02j5JuZWZKnO+m3yeZc2i+t/wb4eEnxmJm1pDzJdHxEXA9sBYiIl3ATKTOzHeRJps9L2pes0onKzKGlRmVm1mLy1OZ/kmwa5ldLuhOYALy31KjMzFpMntr8eyX9NXAwWVfS1e6rb2a2ozx3pgBHAFPT/tMlERFXlRaVmVmL6TeZSvoO8GpgBdsrngJwMjUzS/LcmXYDh0ZElB2MmVmrylOb/wDwX8oOxMysleW5Mx0PPCjpbnYc6OSk0qIyM2sxeZLp+WUHYWbW6vI0jfq5pInAG1PR3RGxrtywzMxaS56BTk4F7gbeB5wKLJWUu9G+pDZJyyX9KK0fIGmppDWSrpO0eyrfI62vSdunVp1jbipfLWnGAP9GM7PS5amA+izwxoiYFREfIGtz+q8DuMbHgIeq1r8IXBIRrwGeBSojUJ0FPJvKL0n7IelQ4HTgtcDxwNcktQ3g+mZmpcuTTHfb6bH+mZzHIWky8N+Ay9O6yAaVviHtsgCYmZZPTuuk7e9I+58MXBsRL0bE74A1ZAndzKxp5KmA+omkxcA1af004Jac5/8K8M/APml9X2BjGnkKYC3QlZa7gMchG5lK0nNp/y7grqpzVh9jZtYU8lRAzZF0CvCWVDQ/Im7q7zhJ7wLWRcQySW8fUpQ5SJoNzAaYMmVK2ZczM9tB3r75vyTrSroVuCfnMUcDJ0k6EdgTeDlwKdApaUy6O50M9Kb9e4H9gbWSxgCvIHulUCmvqD5mm4iYD8wH6O7udm8tMxtWeWrzP0RWm/8esqH37pL09/0dFxFzI2JyREwlq0C6LSLeD9zO9iH8ZgE3p+VFaZ20/bbUhXURcHqq7T8AOCjFY2bWNPLcmc4BpkXEMwBpoOhfAlcO8pqfAa6VdCGwHLgilV8BfEfSGmADWQImIlZJuh54EHgJ+EhEeKR/M2sqeZLpM8Cfqtb/lMpyi4g7gDvS8iP0URsfEf+PrC1rX8d/AfjCQK5pZjac8iTTNWQN9W8mG3rvZOB+SZ8EiIgvlxifmVlLyJNMf5s+FZV3nPv0sa+Z2aiUp2nU54YjEDOzVpZnpP1usi6lr6rePyL+qsS4zMxaSp7H/KvJavRXkrUzNTOzneRJpusjYlHpkZiZtbA8yfQ8SZcDt7LjSPs3lhaVmVmLyZNMzwQOAdrZ/pgfgJOpmVmSJ5m+MSIOLj0SM7MWlmdc0l+mAZrNzKyGPHemRwErJP2O7J2pgHDTKDOz7fIk0+NLj8LMrMX1+5gfEY8BncC706czlZmZWZJnPNOPkTXcf2X6fFfS2WUHZmbWSvI85p8FHBkRzwNI+iLwK+DfywzMzKyV5KnNF9mUJRVbUpmZmSV57ky/RTaeaWUSvZlsHx3fzMzINwTflyXdwfbZSc+MiOWlRmVm1mJqJlNJbwTGR8SPI+Je4N5UfqKk3SJi2XAFaWbW7Oq9M/0i2SR2O1sFzCsnHDOz1lQvme7TV3vSVDa+vJDMzFpPvWQ6ts62vYoOxMysldVLpj+T9AVJ25pBKXMBcFv5oZmZtY56tfmfAi4H1khakcpeD/QAHyo5LjOzllIzmaYeT2dIOhB4bSpeFRGPDEtkZkO0cHkv8xav5omNm9ivs4M5Mw5m5rSuRodlI1SedqaPAE6g1lIWLu9l7o0r2bQ567zXu3ETc29cCeCEaqXI053UrOXMW7x6WyKt2LR5C/MWr25QRDbSOZnaiPTExk0DKjcbqprJVNK4ep/+TixpT0l3S7pP0ipJn0vlB0haKmmNpOsk7Z7K90jra9L2qVXnmpvKV0uaUcDfbSPcfp0dAyo3G6p6d6bLyGrulwHrgd8AD6flPF1JXwSOjYjXA4cDx0s6iqxn1SUR8RrgWbIh/kjfz6byS9J+pPmnTierBDse+JqktgH8jTYKzZlxMB3tO/4z6WhvY84Mzw1p5aiZTCPigIg4EPgZ8O6IGB8R+wLvAn7a34kj8+e02p4+ARwL3JDKF5CNQgVwclonbX9HauN6MnBtRLwYEb8D1gBH5P8TbTSaOa2Li045jK7ODgR0dXZw0SmHufLJSpNrQr2I+HBlJSJ+LOlLeU6e7iCXAa8Bvgr8FtgYES+lXdYClX/dXcDj6RovSXoO2DeV31V12upjzGqaOa3LydOGTZ4KqCcknStpavp8Fngiz8kjYktEHA5MJrubPGTwodYnabakHkk969evL+syZmZ9ypNMzwAmADcBN6blMwZykYjYCNwOvAnolFS5I54M9KblXmB/gLT9FcAz1eV9HFN9jfkR0R0R3RMmTBhIeGZmQ5an0f4G4GOS9q7MA5WHpAnA5ojYKKkDeCdZpdLtwHuBa4FZwM3pkEVp/Vdp+20REZIWAd+T9GVgP+Ag4O68cdjo5N5PNtz6TaaS3kzWR/9lwBRJrwf+ISL+qZ9DJwEL0nvT3YDrI+JHkh4ErpV0IbCc7VOgXAF8R9IaYANZDT4RsUrS9WRjq74EfCQitmBWg3s/WSMoIurvIC0lu1NcFBHTUtkDEfG6YYhvULq7u6Onp6fRYViDHH3xbfT20Ti/q7ODO885tgER2UghaVlEdPe1LVcPqIh4fKci3xla03LvJ2uEPMn08fSoH5LaJX0aeKjkuMwGzb2frBHyJNN/BD5C1razl6w3U3/vS80axr2frBHyNNo/OCLeX10g6WjgznJCMhuaSiWTa/NtOOVJpv8OTM9RZtY03PvJhlvNZCrpTcCbgQmSPlm16eWABxoxM6tS7850d7K2pWOAfarK/0jWVMrMzJJ6c0D9HPi5pG9HxGPDGJOZWcvJU5t/uaTOyoqksZIWlxeSmVnryZNMx6eBSgCIiGeBV5YWkZlZC8qTTLdKmlJZkfQqskGezcwsydM06rPA/5X0c0DAW4HZpUZlZtZi8gzB9xNJ04GjUtHHI+IP5YZlZtZa6s1Oekj6ng5MIRtd/wmyYfjcYN/MrEq9O9NPAR8G/q2PbZWJ8cwGzQM420hSr53ph9P3McMXjo0WHsDZRpp63UlPqXdgRNxYfDg2WsxbvHpbIq3YtHkL8xavdjK1llTvMf/d6fuVZH30b0vrxwC/JJtcz2xQPICzjTT1HvPPBJD0U+DQiHgyrU8Cvj0s0dmItV9nR59Ti3gAZ2tVeRrt719JpMnTZLX7ZoPmAZxtpMnTaP/W1Bf/mrR+GvCz8kKy0cADONtI0+/spACS3gO8La3+Z0TcVGpUQ+TZSRvLTZ5spKo3O2neZPoq4KCI+JmkvYC2iPhTwXEWxsm0cXZu8gTQvpt42Z5j2PjCZidXa2lDmupZ0oeBG4BvpqIuYGFh0dmI0leTp81bg2df2EywvT3pwuW9jQnQrCR5KqA+AhxNNsI+EfEwHoLPasjTtKnSntRsJMmTTF+MiL9UViSNwUPwWQ15mza5PamNNHmS6c8l/QvQIemdwPeBH5YblrWqvpo89cXtSW2kyZNMPwOsB1YC/wDcApxbZlDWumZO6+KiUw6jq7MDAZ0d7bS3aYd93J7URqK67UwltQGrIuIQ4D8GcmJJ+wNXARPJXgvMj4hLJY0DrgOmAo8Cp0bEs5IEXAqcCLwAfDAi7k3nmsX2BH5hRCwYSCyWz2CbNPV13J3nHFt3u2vzbaTpt2mUpJuBsyPi9wM6cdbtdFJE3CtpH2AZMBP4ILAhIi6WdA4wNiI+I+lE4GyyZHokcGlEHJmSbw/QTZaUlwFvSHNR9clNowauryZNHe1tXHTKYXUT32CPM2tFQ2oaBYwFVkm6VdKiyqe/gyLiycqdZWqT+hBZs6qTgcqd5QKyBEsqvyoydwGdKSHPAJZExIaUQJcAx+eI2wag3ihOfVm4vJejL76Nj1+3YkDHmY1UebqT/utQLyJpKjANWApMrOrr/xTZawDIEu3jVYetTWW1yq1A9UZxOnfhSq5Z+jhbImiTOOrAsdz7++d2SaJ5zmc2UtUbz3RP4B+B15BVPl0RES8N9AKSXgb8gGzuqD9mr0YzERGSCmlmJWk2aaK/KVM8DstAde7VzrMvbN6lfPcxu/Hdu7a/4dkSwZ2/3dDv+Vxbb6NNvcf8BWTvKVcCJ9D39CV1SWonS6RXVw0m/XR6fK+8V12XynuB/asOn5zKapXvICLmR0R3RHRPmDBhoKGOerVenb/40tYBn8u19TYa1XvMPzQiDgOQdAVw90BOnGrnrwAeiogvV21aBMwCLk7fN1eVf1TStWQVUM9FxJNpxKr/JWls2u84YO5AYhnt8tSmP7dp17vSwehybb2NUvWS6bb/d0XES9WP5zkdDfx3YKWkFansX8iS6PWSzgIeA05N224hq8lfQ9Y06sx07Q2SPg/ck/a7ICL6f840IP9cS7UGa87LNfg22tVsGiVpC/B8ZRXoIEtyInvd+fJhiXAQ3DRqu6Mvvq3PJNnV2bFLW9C+mjhNn/KKPt+RHv3qcTz6zCa3HbVRpV7TqHrTlvTfJ9CaXt65luoN1rxzbf4ZR+7PhTMPKz12s1aSp2mUtbB6cy3113Op4sKZhzl5mvUjT6N9a2G15lo65pAJzL1xJb0bN3mcUbMCOJmOcDsPPNLV2cFFpxzG7b9e755LZgXyY/4oMHNa1y6VQ5+4bkWf+7rnktng+M50lKrVQ8k9l8wGx8l0lPK89WbF8mP+KOV5682K5WQ6ivX1LtXMBseP+WZmBXAyNTMrgB/zRzDPvWQ2fJxMR6i8o0WZWTH8mD9CDXROJzMbGt+Ztpi8j+55R4sys2L4zrSFVB7d8wxO4h5OZsOr5uDQrWykDg5da6Dnzo529t5jzA53q4DnszcrWL3BoX1n2kJqTSuycdPmXe5WgT5Hi3IiNSuH35m2kDaJLTmeJDZt3sLcG+9n3N57uFmU2TBxMm0heRJpxabNW7fdybpZlFn5/JjfQrqGUHnkZlFm5XIybSFDHR7PzaLMyuNk2kJmTuuis6N90McHWYsAz/NkVjwn0xZz/kmv3WVQ54HwxHlm5XAybTGVCfKGwu9PzYrnZNqCZk7rGlJlFPj9qVnRnExbVF9zOA2Eu5WaFcvJtEXNnNbF37yhC+XYd+d9PHGeWfFKS6aSrpS0TtIDVWXjJC2R9HD6HpvKJekySWsk3S9petUxs9L+D0uaVVa8zWbh8l6Ovvg2Djjn/9Ssgb/91+up14y/o72Nr5x2OJecdri7lZqVrLSBTiS9DfgzcFVEvC6VfQnYEBEXSzoHGBsRn5F0InA2cCJwJHBpRBwpaRzQA3STtexZBrwhIp6td+1WHuhk4fJezl+0io2bNg/pPF3uQmpWuHoDnZTWnTQi/lPS1J2KTwbenpYXAHcAn0nlV0WW2e+S1ClpUtp3SURsAJC0BDgeuKasuBvp3IUrufqu39e928yjq7ODO885tpCYzCyf4e6bPzEinkzLTwET03IX8HjVfmtTWa3yEaWou1Hw+1CzRmnYQCcREZIKe8cgaTYwG2DKlClFnbZ0O8/VNFgCjw5l1kDDnUyfljQpIp5Mj/HrUnkvsH/VfpNTWS/bXwtUyu/o68QRMR+YD9k702LDLk9fczUNVJvEv536eidRswYa7qZRi4BKjfws4Oaq8g+kWv2jgOfS64DFwHGSxqaa/+NSWcur1NbXGvB5ILZEuIuoWYOVdmcq6Rqyu8rxktYC5wEXA9dLOgt4DDg17X4LWU3+GuAF4EyAiNgg6fPAPWm/CyqVUc0qz4R3RT3aV6t0EfXdqVljlFmbf0aNTe/oY98APlLjPFcCVxYYWmnyzFW/cHkvn7huxZBr7PviLqJmjeOR9gtUa676T11/37b1Od+/r5RECu4iatZITqYFqnVnWHmnuWf7bmzeWk4qdZMos8Zy3/wC1bsz3LR5C8++MPR2pJ0d7QgYu1f7tmV3ETVrPN+ZFmjOjIMLr1iq1tnRzorzjivl3GY2NL4zLUilFr+/RLpbnmGe+tDR3sb5J712cAebWel8Z1qAhct7mfP9+3K9D335nu25u422SWyNcM8msxbgZFqA8xetyl2xlDeRdrS3+T2oWQtxMi1AEQOUVPPweWatx8m0yXR2tHv4PLMW5GRax85dQ485ZAK3/3r9Ll1F9969jef/UkwNviuZzFqTk2kNfXUN/e5dv9+2vbqraHvbbkAxydSP9matyU2jasjTzKkyuEhR70yHOn2zmTWOk2kNeQcNKWIIvQp3BzVrXU6mNQz3oCFj92r3I75ZC3MyrWHOjIPpaG8blmt1tLdx3rtd8WTWylwBVUPlLvHj160o5fxtElsi3KbUbIRwMq1j5rQu5i1eXeh70YrfXnRi4ec0s8bxY34/jjlkAoMcm8TMRhHfmdawcHkvn/vhqkLGIN2Zm0CZjTxOpn0oY8K7ivY2uQmU2Qjkx/w+FDGXfU1lTQBlZg3lZNqHMmf53Lw1mLd4dWnnN7PGcDLtQ9kN9j0ls9nI43emVcqsdKrmKZnNRh4n02Th8l7m3HAfm7eU+1LTUzKbjUxOpsm8xatLT6Tu7WQ2cjmZJkX3curq7NhlEGkzG7mcTIFzF64s/JyeesRsdBn1tfkLl/fuMIJ+EeT+p2ajTsskU0nHS1otaY2kc4o67+d+uKqoU20TbphvNuq0RDKV1AZ8FTgBOBQ4Q9KhQz3vwuW9Q2oGVesO1H3vzUaflkimwBHAmoh4JCL+AlwLnDzUkw61J9L7j5yyywDSbvpkNjq1SjLtAh6vWl+byraRNFtSj6Se9evX5zrpUHoi/d1RU7hw5mFcdMphdHV2ILI70otOOcw192aj0IipzY+I+cB8gO7u7lxvLffr7BhUk6ixe7Vz4czDgGwAaSdPM2uVO9NeYP+q9cmpbEgG8zgu8HxNZraLVkmm9wAHSTpA0u7A6cCioZ505rQuvnLa4bn3371NXHLa4b4TNbNdtMRjfkS8JOmjwGKgDbgyIgpp0+THdDMrQkskU4CIuAW4pdFxmJn1pVUe883MmpqTqZlZAZxMzcwK4GRqZlYAJ1MzswI4mZqZFcDJ1MysAIoROPimpPXAY4M8fDzwhwLDKYrjGrhmja1Z44Lmja1Z4npVREzoa8OITKZDIaknIrobHcfOHNfANWtszRoXNG9szRpXNT/mm5kVwMnUzKwATqa7mt/oAGpwXAPXrLE1a1zQvLE1a1zb+J2pmVkBfGdqZlYAJ9OkrKmk+7nmlZLWSXqgqmycpCWSHk7fY1O5JF2W4rtf0vSqY2al/R+WNKuAuPaXdLukByWtkvSxZohN0p6S7pZ0X4rrc6n8AElL0/WvSwOII2mPtL4mbZ9ada65qXy1pBlDiavqnG2Slkv6UZPF9aiklZJWSOpJZc3w76xT0g2Sfi3pIUlvaoa4Bi0iRv2HbMDp3wIHArsD9wGHDsN13wZMBx6oKvsScE5aPgf4Ylo+Efgx2cwpRwFLU/k44JH0PTYtjx1iXJOA6Wl5H+A3ZFNsNzS2dP6XpeV2YGm63vXA6an8G8D/SMv/BHwjLZ8OXJeWD02/8R7AAem3byvg9/wk8D3gR2m9WeJ6FBi/U1kz/DtbAHwoLe8OdDZDXIP+expx0Wb7AG8CFletzwXmDtO1p7JjMl0NTErLk4DVafmbwBk77wecAXyzqnyH/QqK8Wbgnc0UG7AXcC9wJFlj7jE7/5ZkMzO8KS2PSftp59+3er8hxDMZuBU4FvhRuk7D40rneZRdk2lDf0vgFcDvSPU2zRLXUD5+zM/0O5X0MJoYEU+m5aeAiWm5Voylxp4eQaeR3QU2PLb0KL0CWAcsIbt72xgRL/VxjW3XT9ufA/YtIy7gK8A/A1vT+r5NEhdAAD+VtEzS7FTW6N/yAGA98K30auRySXs3QVyD5mTaxCL7T23DmltIehnwA+DjEfHH6m2Nii0itkTE4WR3gkcAhwx3DDuT9C5gXUQsa3QsNbwlIqYDJwAfkfS26o0N+i3HkL3i+npETAOeJ3usb3Rcg+ZkmillKulBelrSJID0vS6V14qxlNgltZMl0qsj4sZmig0gIjYCt5M9PndKqsxnVn2NbddP218BPFNCXEcDJ0l6FLiW7FH/0iaIC4CI6E3f64CbyP4j1Ojfci2wNiKWpvUbyJJro+MaNCfTTClTSQ/SIqBSIzmL7H1lpfwDqVbzKOC59Di0GDhO0thU83lcKhs0SQKuAB6KiC83S2ySJkjqTMsdZO9xHyJLqu+tEVcl3vcCt6W7nUXA6alW/QDgIODuwcYVEXMjYnJETCX7t3NbRLy/0XEBSNpb0j6VZbLf4AEa/FtGxFPA45IOTkXvAB5sdFxD0ogXtc34Iast/A3ZO7jPDtM1rwGeBDaT/Zf6LLJ3Z7cCDwM/A8alfQV8NcW3EuiuOs/fA2vS58wC4noL2ePV/cCK9Dmx0bEBfwUsT3E9APzPVH4gWdJZA3wf2COV75nW16TtB1ad67Mp3tXACQX+pm9ne21+w+NKMdyXPqsq/7Yb/Vum8x0O9KTfcyFZbXzD4xrsxz2gzMwK4Md8M7MCOJmamRXAydTMrABOpmZmBXAyNTMrgJOplUrSvmm0ohWSnpLUW7W+e0HXaJd0cRo16F5Jv5J0QhHnbhRJUyX9baPjsPzG9L+L2eBFxDNk7QmRdD7w54j435XtksbE9v7rg/V5skEvXhcRL0qaCPz1EM/ZaFOBvyUbhcpagO9MbdhJ+rakb0haCnxJ0vmSPl21/YE0wAqS/k7ZGKYrJH1TUttO59oL+DBwdkS8CBART0fE9Wn7GcrG8nxA0herjvuzpHnKxkX9maQjJN0h6RFJJ6V9Pijp5lT+sKTzqo7/ZDrnA5I+nsqmKhuX8z/SeX+aemoh6dWSfqJssJFfSDqk6n+LyyT9Ml270mPqYuCt6e/+RKE/gJXCydQaZTLw5oj4ZK0dJP1X4DTg6MgGN9kCvH+n3V4D/D52GoglHb8f8EWyvvKHA2+UNDNt3pusG+drgT8BF5J1T30PcEHVaY4A/oas99X7JHVLegNwJtnwf0cBH5Y0Le1/EPDVdN6N6VjI5jA6OyLeAHwa+FrVNSaR9Tp7F1kShWzQj19ExOERcUmt/42sefgx3xrl+xGxpZ993gG8AbgnGy6ADrYPfJHHG4E7ImI9gKSryQbkXgj8BfhJ2m8l8GJEbJa0kuwRu2JJelWBpBvZ3tX2poh4vqr8rWT9x38XESvSscuAqcpG33oz8P30d0A2AHTFwojYCjyYXlFYC3IytUZ5vmr5JXZ8StozfQtYEBFz65xnDTBF0sv7ujutY3Ns70u9Fai8Itiq7SM9wa5DwPXX//rFquUtZP8B2I1sbNPDcxyjGvtYk/NjvjWDR8mGX0PZ3D4HpPJbgfdKemXaNk7Sq6oPjIgXyEa4ulTb51iaIOl9ZIOI/LWk8eld6xnAzwcY2zvTdTuAmcCdwC+AmZL2SiMxvSeV9Skl+d+lmCrzGb2+n+v+iWzKGGsRTqbWDH4AjJO0Cvgo2ehdRMSDwLlko8TfTzay/qQ+jj+XbNT2B5VNTvgj4I+RDdF2DtlQePcByyLi5j6Or+fuFN/9wA8ioici7gW+nbYtBS6PiOX9nOf9wFmSKqM3ndzP/vcDW5RNHugKqBbgUaPMapD0QbKh3j7a6Fis+fnO1MysAL4zNTMrgO9MzcwK4GRqZlYAJ1MzswI4mZqZFcDJ1MysAE6mZmYF+P8QSQfzoY+rHQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "plt.scatter(mmrf_ae.predict(np.array(valid_patient_genomic)[0:1,:]),np.array(valid_patient_genomic)[0:1,:])\n",
    "plt.xlabel('True Component')\n",
    "plt.ylabel('Predicted Component')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continental-tanzania",
   "metadata": {},
   "source": [
    "## PFS Binary Classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 827,
   "id": "raising-cliff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats(true_pfs,pred_pfs):\n",
    "    metrics = [accuracy_score, precision_score, recall_score, f1_score]\n",
    "    return([np.round(metric(true_pfs, pred_pfs),2) for metric in metrics])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 853,
   "id": "paperback-announcement",
   "metadata": {},
   "outputs": [],
   "source": [
    "pfs_results_df = pd.DataFrame()\n",
    "bin_bor_train_pfs = bor_train_pfs>12\n",
    "bin_bor_valid_pfs = bor_valid_pfs>12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 854,
   "id": "linear-acquisition",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_routine(train_data, train_pfs, val_data, val_pfs, label_str):\n",
    "    best_val = np.inf\n",
    "    best_reg = None\n",
    "    best_alpha = None\n",
    "    \n",
    "    for alpha in [1e-3, 1e-2, 0.1, 1]:\n",
    "\n",
    "        reg = LogisticRegression(penalty='l2', C=alpha, max_iter=3000).fit(train_data, train_pfs)\n",
    "        accuracy, precision, recall, f1 = get_stats(val_pfs, reg.predict(val_data))\n",
    "\n",
    "        if(accuracy > best_val):\n",
    "            best_val = accuracy\n",
    "            best_reg = reg\n",
    "            best_alpha = alpha\n",
    "            \n",
    "    tr_stats = get_stats(train_pfs, reg.predict(train_data))\n",
    "    val_stats = get_stats(val_pfs, reg.predict(val_data))\n",
    "    \n",
    "    return {'Experiment': label_str,\n",
    "                          'Train Accuracy': tr_stats[0],\n",
    "                          'Train Precision': tr_stats[1],\n",
    "                          'Train Recall': tr_stats[2],\n",
    "                          'Train F1': tr_stats[3],\n",
    "                          \n",
    "                          'Val Accuracy': val_stats[0],\n",
    "                          'Val Precision': val_stats[1],\n",
    "                          'Val Recall': val_stats[2],\n",
    "                          'Val F1': val_stats[3]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 855,
   "id": "surface-reliance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw RNA Seq\n",
    "results = reg_routine(bor_train_patient_genomic, bin_bor_train_pfs, bor_valid_patient_genomic, bin_bor_valid_pfs, 'MMRF RNA Seq')\n",
    "pfs_results_df = pfs_results_df.append(results, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 856,
   "id": "herbal-citation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw Labs\n",
    "results = reg_routine(bor_train_patient_meddata, bin_bor_train_pfs, bor_valid_patient_meddata, bin_bor_valid_pfs, 'MMRF Labs')\n",
    "pfs_results_df = pfs_results_df.append(results, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 857,
   "id": "outdoor-intellectual",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNA Seq + Labs\n",
    "tr_compiled = np.concatenate((bor_train_patient_meddata, bor_train_patient_genomic), axis=1)\n",
    "val_compiled = np.concatenate((bor_valid_patient_meddata, bor_valid_patient_genomic), axis=1)\n",
    "results = reg_routine(tr_compiled, bin_bor_train_pfs, val_compiled, bin_bor_valid_pfs, 'MMRF RNA Seq + Labs')\n",
    "pfs_results_df = pfs_results_df.append(results, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 858,
   "id": "english-scale",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mmrf_ae_encode(rna_data):\n",
    "    encoder = keras.Model(inputs=mmrf_ae.input, outputs=mmrf_ae.layers[2].output)\n",
    "    return(encoder(rna_data))\n",
    "\n",
    "def bor_ae_encode(rna_data):\n",
    "    encoder = keras.Model(inputs=bor_ae.input, outputs=bor_ae.layers[2].output)\n",
    "    return(encoder(rna_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 859,
   "id": "expanded-fluid",
   "metadata": {},
   "outputs": [],
   "source": [
    "bor_mmrfae_train = mmrf_ae_encode(bor_train_patient_genomic.values)\n",
    "bor_mmrfae_valid = mmrf_ae_encode(bor_valid_patient_genomic.values)\n",
    "\n",
    "bor_borae_train = bor_ae_encode(bor_train_patient_genomic.values)\n",
    "bor_borae_valid = bor_ae_encode(bor_valid_patient_genomic.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 860,
   "id": "hazardous-forwarding",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nalinisingh/anaconda3/envs/mm_disease_prog/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/nalinisingh/anaconda3/envs/mm_disease_prog/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# MMRF Autoencoded RNA Seq\n",
    "results = reg_routine(bor_mmrfae_train, bin_bor_train_pfs, bor_mmrfae_valid, bin_bor_valid_pfs, 'MMRF AE RNA Seq')\n",
    "pfs_results_df = pfs_results_df.append(results, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 861,
   "id": "complex-tiffany",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nalinisingh/anaconda3/envs/mm_disease_prog/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/nalinisingh/anaconda3/envs/mm_disease_prog/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/nalinisingh/anaconda3/envs/mm_disease_prog/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/nalinisingh/anaconda3/envs/mm_disease_prog/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# MMRF Autoencoded RNA Seq + Labs\n",
    "tr_compiled = np.concatenate((bor_train_patient_meddata, bor_mmrfae_train), axis=1)\n",
    "val_compiled = np.concatenate((bor_valid_patient_meddata, bor_mmrfae_valid), axis=1)\n",
    "results = reg_routine(tr_compiled, bin_bor_train_pfs, val_compiled, bin_bor_valid_pfs, 'MMRF AE RNA Seq + Labs')\n",
    "pfs_results_df = pfs_results_df.append(results, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 862,
   "id": "persistent-implementation",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nalinisingh/anaconda3/envs/mm_disease_prog/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/nalinisingh/anaconda3/envs/mm_disease_prog/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/nalinisingh/anaconda3/envs/mm_disease_prog/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# MMRF Bortezomib Autoencoded RNA Seq\n",
    "results = reg_routine(bor_borae_train, bin_bor_train_pfs, bor_borae_valid, bin_bor_valid_pfs, 'Bor AE RNA Seq')\n",
    "pfs_results_df = pfs_results_df.append(results, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 863,
   "id": "weekly-hometown",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nalinisingh/anaconda3/envs/mm_disease_prog/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/nalinisingh/anaconda3/envs/mm_disease_prog/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/nalinisingh/anaconda3/envs/mm_disease_prog/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/nalinisingh/anaconda3/envs/mm_disease_prog/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# MMRF Autoencoded RNA Seq + Labs\n",
    "tr_compiled = np.concatenate((bor_train_patient_meddata, bor_borae_train), axis=1)\n",
    "val_compiled = np.concatenate((bor_valid_patient_meddata, bor_borae_valid), axis=1)\n",
    "results = reg_routine(tr_compiled, bin_bor_train_pfs, val_compiled, bin_bor_valid_pfs, 'Bor AE RNA Seq + Labs')\n",
    "pfs_results_df = pfs_results_df.append(results, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 864,
   "id": "alternative-signal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Experiment</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Train F1</th>\n",
       "      <th>Train Precision</th>\n",
       "      <th>Train Recall</th>\n",
       "      <th>Val Accuracy</th>\n",
       "      <th>Val F1</th>\n",
       "      <th>Val Precision</th>\n",
       "      <th>Val Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MMRF RNA Seq</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MMRF Labs</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MMRF RNA Seq + Labs</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MMRF AE RNA Seq</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MMRF AE RNA Seq + Labs</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Bor AE RNA Seq</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bor AE RNA Seq + Labs</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Experiment  Train Accuracy  Train F1  Train Precision  \\\n",
       "0            MMRF RNA Seq            1.00      1.00             1.00   \n",
       "1               MMRF Labs            0.80      0.85             0.80   \n",
       "2     MMRF RNA Seq + Labs            1.00      1.00             1.00   \n",
       "3         MMRF AE RNA Seq            0.76      0.82             0.77   \n",
       "4  MMRF AE RNA Seq + Labs            0.78      0.84             0.80   \n",
       "5          Bor AE RNA Seq            0.73      0.80             0.75   \n",
       "6   Bor AE RNA Seq + Labs            0.80      0.85             0.81   \n",
       "\n",
       "   Train Recall  Val Accuracy  Val F1  Val Precision  Val Recall  \n",
       "0          1.00          0.57    0.62           0.65        0.60  \n",
       "1          0.90          0.56    0.66           0.60        0.73  \n",
       "2          1.00          0.57    0.62           0.65        0.60  \n",
       "3          0.88          0.66    0.72           0.70        0.75  \n",
       "4          0.88          0.60    0.67           0.65        0.69  \n",
       "5          0.85          0.60    0.70           0.63        0.77  \n",
       "6          0.89          0.59    0.68           0.63        0.75  "
      ]
     },
     "execution_count": 864,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pfs_results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
